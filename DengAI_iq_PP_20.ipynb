{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from  sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_outliers_tukey(x):\n",
    "    q1 = np.percentile(x, 25)\n",
    "    q3 = np.percentile(x, 75)\n",
    "    iqr = q3-q1 \n",
    "    floor = q1 - 1.5*iqr\n",
    "    ceiling = q3 + 1.5*iqr\n",
    "    outlier_indices = list(x.index[(x < floor)|(x > ceiling)])\n",
    "    outlier_values = list(x[outlier_indices])\n",
    "    return outlier_indices, outlier_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histogram(x):\n",
    "    plt.hist(x, color='gray', alpha=0.5)\n",
    "    plt.title(\"Histogram of '{var_name}'\".format(var_name=x.name))\n",
    "    plt.xlabel(\"Value\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_stat(X_stat):\n",
    "    for names in X_stat.drop(columns=['city','year','weekofyear','week_start_date']):\n",
    "        X_stat['month_avg_'+names] = X_stat[names].rolling(3 ,min_periods=1).mean()\n",
    "        X_stat['month_min_'+names] = X_stat[names].rolling(3 ,min_periods=1).min()\n",
    "        X_stat['month_max_'+names] = X_stat[names].rolling(3 ,min_periods=1).max()\n",
    "        X_stat['lag_3_'+names] = X_stat[names].shift(4)\n",
    "        X_stat['byte_'+names] = X_stat[names].shift(1)\n",
    "    return X_stat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_correlation(data, threshold=0.9):\n",
    "    corr_mat = data.corr()\n",
    "    corr_mat.loc[:, :] = np.tril(corr_mat, k=-1)\n",
    "    already_in = set()\n",
    "    result = []\n",
    "    for col in corr_mat:\n",
    "        perfect_corr = corr_mat[col][abs(corr_mat[col])> threshold].index.tolist()\n",
    "        if perfect_corr and col not in already_in:\n",
    "            already_in.update(set(perfect_corr))\n",
    "            perfect_corr.append(col)\n",
    "            result.append(perfect_corr)\n",
    "    select_nested = [f[1:] for f in result]\n",
    "    select_flat = [i for j in select_nested for i in j]\n",
    "    return select_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PP_Y(par_Y):\n",
    "    par_Y = par_Y[(par_Y['city']=='iq')]\n",
    "    return par_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PP_X(par_X):\n",
    "    par_X['week_start_date'] = pd.to_datetime(par_X['week_start_date'])\n",
    "#     par_X = par_X[(par_X['city']=='iq')]\n",
    "    par_X = generate_stat(par_X)\n",
    "    par_X = par_X.drop(columns=[\n",
    "        'weekofyear', \n",
    "        'week_start_date',\n",
    "        'year',\n",
    "        'city',\n",
    "        \n",
    "    ])\n",
    "    par_X = par_X.fillna(method = 'bfill')\n",
    "    par_X = par_X.fillna(method = 'ffill')\n",
    "    return par_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"dengue_features_train.csv\")\n",
    "Y = pd.read_csv(\"dengue_labels_train.csv\")\n",
    "X_New = pd.read_csv(\"dengue_features_test.csv\")\n",
    "Y_New = pd.read_csv('submission_format.csv')\n",
    "Xrf = X[(X['city'] == 'iq')]\n",
    "Yrf = Y[(X['city'] == 'iq')]['total_cases'].values.ravel()\n",
    "Y_New = Y_New[(Y_New['city'] == 'iq')]\n",
    "X_New = X_New[(X_New['city'] == 'iq')]\n",
    "X_train, X_test, Y_train, Y_test = Xrf[:int(len(Xrf)*0.8)], Xrf[int(len(Xrf)*0.8):] , Yrf[:int(len(Yrf)*0.8)] , Yrf[int(len(Yrf)*0.8):]\n",
    "X_train, X_test , X_New = PP_X(X_train),PP_X(X_test) , PP_X(X_New)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xrf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = KMeans(n_clusters=5, random_state=0)\n",
    "fit = db.fit(X_train)\n",
    "fit.predict(X_test)\n",
    "\n",
    "# core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "# core_samples_mask[db.core_sample_indices_] = True\n",
    "# labels = db.labels_\n",
    "# n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "# n_clusters_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X , Y = X.loc[Y['total_cases'] <40] , Y.loc[Y['total_cases'] <40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=10)\n",
    "X2 = pd.DataFrame(pca.fit_transform(X),index=X.index)\n",
    "X = pd.concat([X,X2],axis=1)\n",
    "X_New2 = pd.DataFrame(pca.transform(X_New), index = X_New.index)\n",
    "X_New = pd.concat([X_New,X_New2],axis=1)\n",
    "\n",
    "# X = pd.DataFrame(pca.fit_transform(X),index=X.index)\n",
    "# X_New = pd.concat([X_New,X_New2],axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## itteratively drop columns with high absalute correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = find_correlation(X_train , 0.9)\n",
    "X_test = X_test.drop(columns=columns_to_drop)\n",
    "X_train = X_train.drop(columns=columns_to_drop)\n",
    "X_New = X_New.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_crr = X_train.copy(deep=True)\n",
    "X_crr['total_cases'] = Y['total_cases']\n",
    "corr = X_crr.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_features=abs(corr).total_cases.drop('total_cases').sort_values(ascending=False)[:10].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor()\n",
    "model1 = rf.fit(X_train,Y_train)\n",
    "predict = rf.predict(X_test)                                              \n",
    "print(mean_absolute_error(Y_test, predict.round(0).astype(int)))  \n",
    "Y_rf = model1.predict(X_New)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15))\n",
    "importance = rf.feature_importances_\n",
    "feat_importances_act = pd.Series(importance, index=X_train.columns)\n",
    "feat_importances = feat_importances_act.nlargest(20)\n",
    "feat_importances.plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "reg = linear_model.Lasso (alpha = 0.0005 , positive=True)\n",
    "reg.fit(X_train[linear_features],Y_train)\n",
    "predict2 = reg.predict(X_test[linear_features])    \n",
    "print(mean_absolute_error(Y_test, [max(x,0) for x in predict2.round(0).astype(int)]))\n",
    "predict_New2 = reg.predict(X_New[linear_features])\n",
    "predict_New2= [max(x,0) for x in predict_New2]\n",
    "predict_New2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "model_nb = sm.GLM(Y_train,X_train, family=sm.families.NegativeBinomial()).fit()\n",
    "predict2 = model_nb.predict(X_test)\n",
    "print(mean_absolute_error(Y_test, [max(x,0) for x in predict2.round(0).astype(int)]))\n",
    "predict_New2 = model_nb.predict(X_New)\n",
    "predict_New2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.predict(X_testrf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf = svm.SVC()\n",
    "clf.fit(X_train[feat_importances_act.nlargest(10).keys()],Y_train)\n",
    "predict3 = clf.predict(X_test[feat_importances_act.nlargest(10).keys()])     \n",
    "print(mean_absolute_error(Y_test, predict3.round(0).astype(int)))  \n",
    "clf.predict(X_testrf[feat_importances_act.nlargest(10).keys()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_New['total_cases'] = np.array(predict_New2, dtype=np.float32).round(0)\n",
    "Y_New['total_cases'] = Y_New['total_cases'].astype(int)\n",
    "Y_New.to_csv('submission_iq.csv')\n",
    "Y_New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_absolute_error(Y_test, predict2.round(0).astype(int)))  \n",
    "predict_avg = (predict+predict2)/2\n",
    "print(mean_absolute_error(Y_test, predict_avg.round(0).astype(int)))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15))\n",
    "abs(corr).total_cases.drop('total_cases').sort_values(ascending=False)[:10].plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15))\n",
    "sns.heatmap(corr, \n",
    "        xticklabels=corr.columns,\n",
    "        yticklabels=corr.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
